{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Cassandra latest time is 2024-06-16 13:22:00\n",
      "MySQL latest time is 2024-06-16 13:22:00\n",
      "No new data found\n",
      "Job takes 15.649436 seconds to execute\n",
      "--------------------------------------------------\n",
      "Cassandra latest time is 2024-06-16 13:22:00\n",
      "MySQL latest time is 2024-06-16 13:22:00\n",
      "No new data found\n",
      "Job takes 1.492338 seconds to execute\n",
      "--------------------------------------------------\n",
      "Cassandra latest time is 2024-06-16 13:22:00\n",
      "MySQL latest time is 2024-06-16 13:22:00\n",
      "No new data found\n",
      "Job takes 0.706121 seconds to execute\n",
      "--------------------------------------------------\n",
      "Cassandra latest time is 2024-06-16 13:32:27\n",
      "MySQL latest time is 2024-06-16 13:22:00\n",
      "------ Data Warehouse --------\n",
      "The host is: localhost\n",
      "The port using is:  3306\n",
      "The db using is:  Data_Warehouse\n",
      "------------------------------\n",
      "Retrieving data from Cassandra\n",
      "------------------------------\n",
      "------------------------------\n",
      "Selecting data from Cassandra\n",
      "------------------------------\n",
      "root\n",
      " |-- ts: string (nullable = true)\n",
      " |-- job_id: double (nullable = true)\n",
      " |-- custom_track: string (nullable = true)\n",
      " |-- bid: double (nullable = true)\n",
      " |-- campaign_id: double (nullable = true)\n",
      " |-- group_id: double (nullable = true)\n",
      " |-- publisher_id: double (nullable = true)\n",
      "\n",
      "------------------------------\n",
      "Processing Cassandra Output\n",
      "------------------------------\n",
      "Processing Calculation Clicks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\spark-3.5.0-bin-hadoop3\\python\\pyspark\\sql\\dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Calculation Conversion\n",
      "Processing Calculation Qualified\n",
      "Processing Calculation Unqualified\n",
      "Processing Join Data\n",
      "------------------------------\n",
      "Merge Company Data\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Add column Last Updated Time (CDC) near real time\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Data Final Output\n",
      "-----------------------------\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "|job_id|      date|hour|publisher_id|campaign_id|group_id|bid_set|spend_hour|click|conversion|qualified|unqualified|company_id|    Last_Updated_At|\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "| 878.0|2024-06-16|  13|         1.0|       12.0|    17.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:27|\n",
      "| 551.0|2024-06-16|  13|         4.0|       10.0|    18.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:32:27|\n",
      "| 288.0|2024-06-16|  13|        23.0|       69.0|    11.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:32:27|\n",
      "|1549.0|2024-06-16|  13|        23.0|      221.0|    25.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|       241|2024-06-16 13:32:27|\n",
      "|1300.0|2024-06-16|  13|        31.0|       61.0|    32.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        40|2024-06-16 13:32:27|\n",
      "| 978.0|2024-06-16|  13|        38.0|        1.0|    41.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:32:27|\n",
      "|2050.0|2024-06-16|  13|        12.0|       11.0|    27.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:27|\n",
      "|  93.0|2024-06-16|  13|        16.0|       10.0|    10.0|   NULL|      NULL| NULL|         1|     NULL|       NULL|         1|2024-06-16 13:32:27|\n",
      "|1352.0|2024-06-16|  13|        13.0|       79.0|    22.0|   NULL|      NULL| NULL|      NULL|        1|       NULL|         1|2024-06-16 13:32:27|\n",
      "|1256.0|2024-06-16|  13|        22.0|       61.0|    32.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        40|2024-06-16 13:32:27|\n",
      "|  73.0|2024-06-16|  13|        35.0|       53.0|    15.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:27|\n",
      "| 967.0|2024-06-16|  13|        35.0|       10.0|    25.0|   NULL|      NULL| NULL|      NULL|        1|       NULL|        33|2024-06-16 13:32:27|\n",
      "|1788.0|2024-06-16|  13|        27.0|       48.0|    10.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         3|2024-06-16 13:32:27|\n",
      "|1180.0|2024-06-16|  13|        38.0|       10.0|    21.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:27|\n",
      "| 446.0|2024-06-16|  13|        33.0|        5.0|    10.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:32:27|\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "\n",
      "-----------------------------\n",
      "Import Output to MySQL\n",
      "-----------------------------\n",
      "Data imported successfully\n",
      "Task Finished\n",
      "Job takes 12.115041 seconds to execute\n",
      "--------------------------------------------------\n",
      "Cassandra latest time is 2024-06-16 13:32:48\n",
      "MySQL latest time is 2024-06-16 13:32:27\n",
      "------ Data Warehouse --------\n",
      "The host is: localhost\n",
      "The port using is:  3306\n",
      "The db using is:  Data_Warehouse\n",
      "------------------------------\n",
      "Retrieving data from Cassandra\n",
      "------------------------------\n",
      "------------------------------\n",
      "Selecting data from Cassandra\n",
      "------------------------------\n",
      "root\n",
      " |-- ts: string (nullable = true)\n",
      " |-- job_id: double (nullable = true)\n",
      " |-- custom_track: string (nullable = true)\n",
      " |-- bid: double (nullable = true)\n",
      " |-- campaign_id: double (nullable = true)\n",
      " |-- group_id: double (nullable = true)\n",
      " |-- publisher_id: double (nullable = true)\n",
      "\n",
      "------------------------------\n",
      "Processing Cassandra Output\n",
      "------------------------------\n",
      "Processing Calculation Clicks\n",
      "Processing Calculation Conversion\n",
      "Processing Calculation Qualified\n",
      "Processing Calculation Unqualified\n",
      "Processing Join Data\n",
      "------------------------------\n",
      "Merge Company Data\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Add column Last Updated Time (CDC) near real time\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Data Final Output\n",
      "-----------------------------\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "|job_id|      date|hour|publisher_id|campaign_id|group_id|bid_set|spend_hour|click|conversion|qualified|unqualified|company_id|    Last_Updated_At|\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "|2044.0|2024-06-16|  13|        30.0|       90.0|    18.0|   NULL|      NULL| NULL|      NULL|     NULL|          1|         1|2024-06-16 13:32:48|\n",
      "|1539.0|2024-06-16|  13|        20.0|        1.0|    15.0|   NULL|      NULL| NULL|      NULL|        1|       NULL|         1|2024-06-16 13:32:48|\n",
      "| 137.0|2024-06-16|  13|        28.0|       48.0|    10.0|   NULL|      NULL| NULL|      NULL|     NULL|          1|         1|2024-06-16 13:32:48|\n",
      "| 493.0|2024-06-16|  13|        27.0|       33.0|    10.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:48|\n",
      "|1223.0|2024-06-16|  13|        23.0|       48.0|    10.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:48|\n",
      "|2020.0|2024-06-16|  13|         5.0|       70.0|    27.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:48|\n",
      "|2020.0|2024-06-16|  13|        32.0|      144.0|    41.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:48|\n",
      "| 391.0|2024-06-16|  13|        36.0|      127.0|    27.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:32:48|\n",
      "| 392.0|2024-06-16|  13|        24.0|        1.0|    10.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:32:48|\n",
      "|1213.0|2024-06-16|  13|        30.0|       61.0|    35.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:48|\n",
      "| 454.0|2024-06-16|  13|         3.0|       61.0|    19.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:32:48|\n",
      "|1793.0|2024-06-16|  13|        11.0|        1.0|    16.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         3|2024-06-16 13:32:48|\n",
      "|1808.0|2024-06-16|  13|        10.0|        1.0|    14.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         3|2024-06-16 13:32:48|\n",
      "|  92.0|2024-06-16|  13|        16.0|        1.0|    10.0|   NULL|      NULL| NULL|      NULL|     NULL|          1|         1|2024-06-16 13:32:48|\n",
      "|1386.0|2024-06-16|  13|        34.0|       55.0|    10.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:32:48|\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "\n",
      "-----------------------------\n",
      "Import Output to MySQL\n",
      "-----------------------------\n",
      "Data imported successfully\n",
      "Task Finished\n",
      "Job takes 7.702571 seconds to execute\n",
      "--------------------------------------------------\n",
      "Cassandra latest time is 2024-06-16 13:32:48\n",
      "MySQL latest time is 2024-06-16 13:32:48\n",
      "No new data found\n",
      "Job takes 0.7985 seconds to execute\n",
      "--------------------------------------------------\n",
      "Cassandra latest time is 2024-06-16 13:33:09\n",
      "MySQL latest time is 2024-06-16 13:32:48\n",
      "------ Data Warehouse --------\n",
      "The host is: localhost\n",
      "The port using is:  3306\n",
      "The db using is:  Data_Warehouse\n",
      "------------------------------\n",
      "Retrieving data from Cassandra\n",
      "------------------------------\n",
      "------------------------------\n",
      "Selecting data from Cassandra\n",
      "------------------------------\n",
      "root\n",
      " |-- ts: string (nullable = true)\n",
      " |-- job_id: double (nullable = true)\n",
      " |-- custom_track: string (nullable = true)\n",
      " |-- bid: double (nullable = true)\n",
      " |-- campaign_id: double (nullable = true)\n",
      " |-- group_id: double (nullable = true)\n",
      " |-- publisher_id: double (nullable = true)\n",
      "\n",
      "------------------------------\n",
      "Processing Cassandra Output\n",
      "------------------------------\n",
      "Processing Calculation Clicks\n",
      "Processing Calculation Conversion\n",
      "Processing Calculation Qualified\n",
      "Processing Calculation Unqualified\n",
      "Processing Join Data\n",
      "------------------------------\n",
      "Merge Company Data\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Add column Last Updated Time (CDC) near real time\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Data Final Output\n",
      "-----------------------------\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "|job_id|      date|hour|publisher_id|campaign_id|group_id|bid_set|spend_hour|click|conversion|qualified|unqualified|company_id|    Last_Updated_At|\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "|1226.0|2024-06-16|  13|        37.0|        5.0|    41.0|   NULL|      NULL| NULL|      NULL|     NULL|          1|         1|2024-06-16 13:33:09|\n",
      "| 663.0|2024-06-16|  13|         3.0|       11.0|    26.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:33:09|\n",
      "| 491.0|2024-06-16|  13|         2.0|       61.0|    41.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         8|2024-06-16 13:33:09|\n",
      "| 920.0|2024-06-16|  13|        12.0|      117.0|    32.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|       165|2024-06-16 13:33:09|\n",
      "| 423.0|2024-06-16|  13|        34.0|        1.0|    25.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:33:09|\n",
      "| 618.0|2024-06-16|  13|        23.0|       58.0|    18.0|   NULL|      NULL| NULL|      NULL|     NULL|          1|        33|2024-06-16 13:33:09|\n",
      "|1528.0|2024-06-16|  13|        27.0|       48.0|    41.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:33:09|\n",
      "| 502.0|2024-06-16|  13|         9.0|        1.0|    10.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:33:09|\n",
      "|1416.0|2024-06-16|  13|        11.0|       11.0|    18.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:33:09|\n",
      "|1122.0|2024-06-16|  13|        34.0|       61.0|    16.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         3|2024-06-16 13:33:09|\n",
      "| 102.0|2024-06-16|  13|        32.0|      193.0|    26.0|   NULL|      NULL| NULL|         1|     NULL|       NULL|         1|2024-06-16 13:33:09|\n",
      "|1700.0|2024-06-16|  13|        33.0|        1.0|    11.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         3|2024-06-16 13:33:09|\n",
      "|1555.0|2024-06-16|  13|        20.0|       10.0|    32.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         3|2024-06-16 13:33:09|\n",
      "|1261.0|2024-06-16|  13|        28.0|        1.0|    35.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        40|2024-06-16 13:33:09|\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "\n",
      "-----------------------------\n",
      "Import Output to MySQL\n",
      "-----------------------------\n",
      "Data imported successfully\n",
      "Task Finished\n",
      "Job takes 6.033179 seconds to execute\n",
      "--------------------------------------------------\n",
      "Cassandra latest time is 2024-06-16 13:33:30\n",
      "MySQL latest time is 2024-06-16 13:33:09\n",
      "------ Data Warehouse --------\n",
      "The host is: localhost\n",
      "The port using is:  3306\n",
      "The db using is:  Data_Warehouse\n",
      "------------------------------\n",
      "Retrieving data from Cassandra\n",
      "------------------------------\n",
      "------------------------------\n",
      "Selecting data from Cassandra\n",
      "------------------------------\n",
      "root\n",
      " |-- ts: string (nullable = true)\n",
      " |-- job_id: double (nullable = true)\n",
      " |-- custom_track: string (nullable = true)\n",
      " |-- bid: double (nullable = true)\n",
      " |-- campaign_id: double (nullable = true)\n",
      " |-- group_id: double (nullable = true)\n",
      " |-- publisher_id: double (nullable = true)\n",
      "\n",
      "------------------------------\n",
      "Processing Cassandra Output\n",
      "------------------------------\n",
      "Processing Calculation Clicks\n",
      "Processing Calculation Conversion\n",
      "Processing Calculation Qualified\n",
      "Processing Calculation Unqualified\n",
      "Processing Join Data\n",
      "------------------------------\n",
      "Merge Company Data\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Add column Last Updated Time (CDC) near real time\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "Data Final Output\n",
      "-----------------------------\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "|job_id|      date|hour|publisher_id|campaign_id|group_id|bid_set|spend_hour|click|conversion|qualified|unqualified|company_id|    Last_Updated_At|\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "| 180.0|2024-06-16|  13|        17.0|       12.0|    17.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:33:30|\n",
      "| 317.0|2024-06-16|  13|        33.0|       12.0|    26.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:33:30|\n",
      "| 418.0|2024-06-16|  13|        32.0|        1.0|    35.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:33:30|\n",
      "| 470.0|2024-06-16|  13|        20.0|       61.0|    16.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:33:30|\n",
      "| 502.0|2024-06-16|  13|        10.0|       48.0|    10.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:33:30|\n",
      "| 543.0|2024-06-16|  13|        20.0|       10.0|    10.0|   NULL|      NULL| NULL|      NULL|        1|       NULL|        33|2024-06-16 13:33:30|\n",
      "| 546.0|2024-06-16|  13|        37.0|       12.0|    10.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:33:30|\n",
      "| 587.0|2024-06-16|  13|        15.0|       11.0|    32.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:33:30|\n",
      "| 653.0|2024-06-16|  13|         3.0|       10.0|    32.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:33:30|\n",
      "| 735.0|2024-06-16|  13|         5.0|        1.0|    10.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:33:30|\n",
      "| 963.0|2024-06-16|  13|        36.0|        5.0|    12.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|        33|2024-06-16 13:33:30|\n",
      "|1001.0|2024-06-16|  13|        35.0|      193.0|    10.0|   NULL|      NULL| NULL|         1|     NULL|       NULL|         2|2024-06-16 13:33:30|\n",
      "|1397.0|2024-06-16|  13|        22.0|       70.0|    41.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:33:30|\n",
      "|1569.0|2024-06-16|  13|        30.0|       61.0|    41.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         3|2024-06-16 13:33:30|\n",
      "|1795.0|2024-06-16|  13|        22.0|       79.0|    37.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         3|2024-06-16 13:33:30|\n",
      "|1801.0|2024-06-16|  13|        24.0|      103.0|    32.0|    1.0|       1.0|    1|      NULL|     NULL|       NULL|         3|2024-06-16 13:33:30|\n",
      "|1895.0|2024-06-16|  13|        32.0|       61.0|    17.0|   NULL|      NULL| NULL|      NULL|     NULL|          1|         1|2024-06-16 13:33:30|\n",
      "|1973.0|2024-06-16|  13|        10.0|       63.0|    12.0|    0.0|       0.0|    1|      NULL|     NULL|       NULL|         1|2024-06-16 13:33:30|\n",
      "|2042.0|2024-06-16|  13|        33.0|        1.0|    35.0|   NULL|      NULL| NULL|      NULL|        1|       NULL|         1|2024-06-16 13:33:30|\n",
      "+------+----------+----+------------+-----------+--------+-------+----------+-----+----------+---------+-----------+----------+-------------------+\n",
      "\n",
      "-----------------------------\n",
      "Import Output to MySQL\n",
      "-----------------------------\n",
      "Data imported successfully\n",
      "Task Finished\n",
      "Job takes 5.237387 seconds to execute\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 242\u001b[0m\n\u001b[0;32m    240\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time)\u001b[38;5;241m.\u001b[39mtotal_seconds()\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob takes \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds to execute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(execution_time))\n\u001b[1;32m--> 242\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.0-bin-hadoop3\\python\\pyspark\\context.py:382\u001b[0m, in \u001b[0;36mSparkContext._do_init.<locals>.signal_handler\u001b[1;34m(signal, frame)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignal_handler\u001b[39m(signal: Any, frame: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancelAllJobs()\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pyspark --packages com.datastax.spark:spark-cassandra-connector_2.12:3.1.0\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pyspark.sql.functions as sf\n",
    "from uuid import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from uuid import * \n",
    "from uuid import UUID\n",
    "import time_uuid \n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.window import Window as W\n",
    "from pyspark.sql import functions as F\n",
    "    \n",
    "spark = SparkSession.builder.config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.1.0').getOrCreate()\n",
    "\n",
    "def calculating_clicks(df):\n",
    "    clicks_data = df.filter(df.custom_track == 'click')\n",
    "    clicks_data = clicks_data.na.fill({'bid':0})\n",
    "    clicks_data = clicks_data.na.fill({'job_id':0})\n",
    "    clicks_data = clicks_data.na.fill({'publisher_id':0})\n",
    "    clicks_data = clicks_data.na.fill({'group_id':0})\n",
    "    clicks_data = clicks_data.na.fill({'campaign_id':0})\n",
    "    clicks_data.registerTempTable('clicks')\n",
    "    clicks_output = spark.sql(\"\"\" \n",
    "        SELECT \n",
    "            date(ts) as date,\n",
    "            hour(ts) as hour,\n",
    "            job_id,\n",
    "            publisher_id,\n",
    "            campaign_id,\n",
    "            group_id,\n",
    "            round(avg(bid),2) as bid_set, \n",
    "            sum(bid) as spend_hour, \n",
    "            count(*) as click \n",
    "        FROM clicks \n",
    "        GROUP BY date(ts), hour(ts), job_id, publisher_id, campaign_id, group_id \n",
    "    \"\"\")\n",
    "    return clicks_output \n",
    "    \n",
    "def calculating_conversion(df):\n",
    "    conversion_data = df.filter(df.custom_track == 'conversion')\n",
    "    conversion_data = conversion_data.na.fill({'job_id':0})\n",
    "    conversion_data = conversion_data.na.fill({'publisher_id':0})\n",
    "    conversion_data = conversion_data.na.fill({'group_id':0})\n",
    "    conversion_data = conversion_data.na.fill({'campaign_id':0})\n",
    "    conversion_data.registerTempTable('conversion')\n",
    "    conversion_output = spark.sql(\"\"\" \n",
    "        SELECT \n",
    "            date(ts) as date,\n",
    "            hour(ts) as hour,   \n",
    "            job_id,\n",
    "            publisher_id,\n",
    "            campaign_id,\n",
    "            group_id, \n",
    "            count(*) as conversion \n",
    "        FROM conversion \n",
    "        GROUP BY date(ts), hour(ts), job_id, publisher_id, campaign_id, group_id \n",
    "    \"\"\")\n",
    "    return conversion_output \n",
    "    \n",
    "def calculating_qualified(df):    \n",
    "    qualified_data = df.filter(df.custom_track == 'qualified')\n",
    "    qualified_data = qualified_data.na.fill({'job_id':0})\n",
    "    qualified_data = qualified_data.na.fill({'publisher_id':0})\n",
    "    qualified_data = qualified_data.na.fill({'group_id':0})\n",
    "    qualified_data = qualified_data.na.fill({'campaign_id':0})\n",
    "    qualified_data.registerTempTable('qualified')\n",
    "    qualified_output = spark.sql(\"\"\" \n",
    "        SELECT \n",
    "            date(ts) as date,\n",
    "            hour(ts) as hour,\n",
    "            job_id,\n",
    "            publisher_id,\n",
    "            campaign_id,\n",
    "            group_id, \n",
    "            count(*) as qualified \n",
    "        FROM qualified \n",
    "        GROUP BY date(ts), hour(ts), job_id, publisher_id, campaign_id, group_id \n",
    "    \"\"\")\n",
    "    return qualified_output\n",
    "    \n",
    "def calculating_unqualified(df):\n",
    "    unqualified_data = df.filter(df.custom_track == 'unqualified')\n",
    "    unqualified_data = unqualified_data.na.fill({'job_id':0})\n",
    "    unqualified_data = unqualified_data.na.fill({'publisher_id':0})\n",
    "    unqualified_data = unqualified_data.na.fill({'group_id':0})\n",
    "    unqualified_data = unqualified_data.na.fill({'campaign_id':0})\n",
    "    unqualified_data.registerTempTable('unqualified')\n",
    "    unqualified_output = spark.sql(\"\"\" \n",
    "        SELECT \n",
    "            date(ts) as date,\n",
    "            hour(ts) as hour,\n",
    "            job_id,\n",
    "            publisher_id,\n",
    "            campaign_id,\n",
    "            group_id, \n",
    "            count(*) as unqualified \n",
    "        FROM unqualified \n",
    "        GROUP BY date(ts), hour(ts), job_id, publisher_id, campaign_id, group_id \n",
    "    \"\"\")\n",
    "    return unqualified_output\n",
    "    \n",
    "def process_final_data(clicks_output,conversion_output,qualified_output,unqualified_output):\n",
    "    final_data = clicks_output.join(conversion_output,['job_id','date','hour','publisher_id','campaign_id','group_id'],'full').\\\n",
    "    join(qualified_output,['job_id','date','hour','publisher_id','campaign_id','group_id'],'full').\\\n",
    "    join(unqualified_output,['job_id','date','hour','publisher_id','campaign_id','group_id'],'full')\n",
    "    return final_data \n",
    "    \n",
    "def process_cassandra_data(df):\n",
    "    print('Processing Calculation Clicks')\n",
    "    clicks_output = calculating_clicks(df)\n",
    "    print('Processing Calculation Conversion')\n",
    "    conversion_output = calculating_conversion(df)\n",
    "    print('Processing Calculation Qualified')\n",
    "    qualified_output = calculating_qualified(df)\n",
    "    print('Processing Calculation Unqualified')\n",
    "    unqualified_output = calculating_unqualified(df)\n",
    "    print('Processing Join Data')\n",
    "    final_data = process_final_data(clicks_output,conversion_output,qualified_output,unqualified_output)\n",
    "    return final_data\n",
    "    \n",
    "def retrieve_company_data(url,driver,user,password):\n",
    "    sql = \"\"\"(SELECT id as job_id, company_id, group_id, campaign_id FROM job) test\"\"\"\n",
    "    company = spark.read.format('jdbc').options(url=url, driver=driver, dbtable=sql, user=user, password=password).load()\n",
    "    return company \n",
    "    \n",
    "def import_to_mysql(output):\n",
    "    final_output = output.select('job_id','date','hour','publisher_id','company_id','campaign_id','group_id','unqualified','qualified','conversion','click','bid_set','spend_hour', 'Last_Updated_At')\n",
    "    # final_output = final_output.withColumnRenamed('date','dates').withColumnRenamed('hour','hours').withColumnRenamed('qualified','qualified_application').\\\n",
    "    # withColumnRenamed('unqualified','disqualified_application').withColumnRenamed('conversions','conversion')\n",
    "    final_output = final_output.withColumn('sources',lit('Cassandra'))\n",
    "    final_output.write.format(\"jdbc\") \\\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/Data_Warehouse\") \\\n",
    "    .option(\"dbtable\", \"events_etl\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"user\", \"root\") \\\n",
    "    .option(\"password\", \"1\") \\\n",
    "    .save()\n",
    "    return print('Data imported successfully')\n",
    "\n",
    "def last_updated_time(df, final_output):\n",
    "    last_update_time = df.select(F.max(\"ts\")).collect()[0][0]\n",
    "    final_output = final_output.withColumn(\"Last_Updated_At\", F.lit(last_update_time))\n",
    "    return final_output\n",
    "\n",
    "def main_task(mysql_time):\n",
    "    host = 'localhost'\n",
    "    port = '3306'\n",
    "    db_name = 'Data_Warehouse'\n",
    "    user = 'root'\n",
    "    password = '1'\n",
    "    url = 'jdbc:mysql://' + host + ':' + port + '/' + db_name\n",
    "    driver = \"com.mysql.cj.jdbc.Driver\"\n",
    "    print('------ Data Warehouse --------')\n",
    "    print('The host is:' ,host)\n",
    "    print('The port using is: ',port)\n",
    "    print('The db using is: ',db_name)\n",
    "    print('------------------------------')\n",
    "    print('Retrieving data from Cassandra')\n",
    "    print('------------------------------')\n",
    "    df = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"tracking\",keyspace=\"study_data_engineering\").load().filter(col('ts') > mysql_time)\n",
    "    print('------------------------------')\n",
    "    print('Selecting data from Cassandra')\n",
    "    print('------------------------------')\n",
    "    df = df.select('ts','job_id','custom_track','bid','campaign_id','group_id','publisher_id')\n",
    "    df = df.filter(df.job_id.isNotNull())\n",
    "    df.printSchema()\n",
    "    print('------------------------------')\n",
    "    print('Processing Cassandra Output')\n",
    "    print('------------------------------')\n",
    "    cassandra_output = process_cassandra_data(df)\n",
    "    print('------------------------------')\n",
    "    print('Merge Company Data')\n",
    "    print('-----------------------------')\n",
    "    company = retrieve_company_data(url,driver,user,password)\n",
    "    join_output = cassandra_output.join(company,'job_id','left').drop(company.group_id).drop(company.campaign_id)\n",
    "    print('-----------------------------')\n",
    "    print('Add column Last Updated Time (CDC) near real time')\n",
    "    print('-----------------------------')\n",
    "    final_output = last_updated_time(df, join_output)\n",
    "    print('-----------------------------')\n",
    "    print('Data Final Output')\n",
    "    print('-----------------------------')\n",
    "    final_output.show()\n",
    "    print('-----------------------------')\n",
    "    print('Import Output to MySQL')\n",
    "    print('-----------------------------')\n",
    "    import_to_mysql(final_output)\n",
    "    return print('Task Finished')\n",
    "    \n",
    "def get_latest_time_cassandra():\n",
    "    data = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table = 'tracking',keyspace = 'study_data_engineering').load()\n",
    "    cassandra_latest_time = data.agg({'ts':'max'}).take(1)[0][0]\n",
    "    return cassandra_latest_time\n",
    "\n",
    "def get_mysql_latest_time(url,driver,user,password):    \n",
    "    sql = \"\"\"(select max(Last_Updated_At) from events_etl) data\"\"\"\n",
    "    mysql_time = spark.read.format('jdbc').options(url=url, driver=driver, dbtable=sql, user=user, password=password).load()\n",
    "    mysql_time = mysql_time.take(1)[0][0]\n",
    "    if mysql_time is None:\n",
    "        mysql_latest = '1998-01-01 23:59:59'\n",
    "    else :\n",
    "        # mysql_latest = mysql_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        mysql_latest = mysql_time\n",
    "    return mysql_latest \n",
    "\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "db_name = 'Data_Warehouse'\n",
    "user = 'root'\n",
    "password = '1'\n",
    "url = 'jdbc:mysql://' + host + ':' + port + '/' + db_name\n",
    "driver = \"com.mysql.cj.jdbc.Driver\"\n",
    "\n",
    "while True :\n",
    "    start_time = datetime.datetime.now()\n",
    "    cassandra_time = get_latest_time_cassandra()\n",
    "    print('--------------------------------------------------')\n",
    "    print('Cassandra latest time is {}'.format(cassandra_time))\n",
    "    mysql_time = get_mysql_latest_time(url,driver,user,password)\n",
    "    print('MySQL latest time is {}'.format(mysql_time))\n",
    "    if cassandra_time > mysql_time : \n",
    "        main_task(mysql_time)\n",
    "    else :\n",
    "        print(\"No new data found\")\n",
    "    end_time = datetime.datetime.now()\n",
    "    execution_time = (end_time - start_time).total_seconds()\n",
    "    print('Job takes {} seconds to execute'.format(execution_time))\n",
    "    time.sleep(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
